{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a185606",
   "metadata": {},
   "source": [
    "###### this notebook shows my attempt (with the references from Kaggle) in understanding the concept of RAG and putting it in practice \n",
    "###### GenAI features used in this practice were by Google\n",
    "###### VectorDB features provided by Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d231621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"/home/uih06736/ds/configs/.env\")\n",
    "key = os.getenv(\"GOOGLE_AI_STUDIO_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=key)\n",
    "\n",
    "# im taking a look at the list of available embeddings model available from the API\n",
    "for m in client.models.list():\n",
    "    if \"embedContent\" in m.supported_actions:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc68aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some strings that represent documents\n",
    "\n",
    "DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\n",
    "DOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\n",
    "DOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead5592",
   "metadata": {},
   "source": [
    "##### CONCEPT: Embeddings\n",
    "###### 1. Embeddings can represent text, images, and soon audio and video.\n",
    "###### 2. They are in the form of vector(s), a numerical representations.\n",
    "###### 3. These vector(s) can help in locating the relevant data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9468172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\" # this vectors is the best representation of the document\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\" # this vectors is the closest representation to the document's vectors\n",
    "\n",
    "        response = client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=embedding_task,\n",
    "            ),\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f11b4e9",
   "metadata": {},
   "source": [
    "##### A vector database is used to store our vectors (embeddings)\n",
    "##### these stored vectors will later be used to compare with the queried vectors(inference results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ed26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"googlecardb\"\n",
    "\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "embed_fn.document_mode = True\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# transforming the string documents created earlier into DOCUMENT embeddings (the realest representation)\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "# inserting the embeddings of my artificial documents \n",
    "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n",
    "db.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbafed2a",
   "metadata": {},
   "source": [
    "##### An Embedding Model can create two different types of vectors—a Document Reference and a Query Probe—that are designed to align perfectly in the vector space, ensuring accurate and efficient retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa01454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to query mode when generating embeddings.\n",
    "embed_fn.document_mode = False\n",
    "\n",
    "# Search the Chroma DB using the specified query.\n",
    "query = \"How do you use the touchscreen, just explain me to touchscreen\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[all_passages] = result[\"documents\"]\n",
    "\n",
    "print(all_passages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "\"\"\"\n",
    "\n",
    "# Add the retrieved documents to the prompt.\n",
    "for passage in all_passages:\n",
    "    passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt)\n",
    "\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b0065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
